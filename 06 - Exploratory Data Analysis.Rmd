---
title: "06 - Exploratory Data Analysis"
output: html_notebook
---

## Overview of Exploratory Data Analysis

Exploratory data analysis (EDA) is a process used to gain better understanding of a data set. The goal is to gain familiarity with the shape and contents of the data. The approach often generates questions that can be further addressed through the use of statisical models and graphs. It is an iterative process that generally involves creating and exploring one or two dimensional summaries of the data that lead to the creation of additional summaries and ultimately an understanding of the data set. It also plays a role in data quality control, an important process by which the integrity of the data is evaluated prior to any decision-making or conclusions are made.

In this lesson we will gain more experience with some of the tools we have discussed through an EDA exercise. For many of the questions we will ask you to answer there is no right or wrong way to answer the question. However, this is an opportunity to further commit some of the new functions you have learned to memory.

## Introduction to data set

In this exercise we will be exploring a snippet of the MIMIC data set. MIMIC is an openly available dataset developed by the MIT Lab for Computational Physiology, comprising deidentified health data associated with ~40,000 critical care patients. It includes demographics, vital signs, laboratory tests, medications, and more. See this publication for additional information:

> MIMIC-III, a freely accessible critical care database. Johnson AEW, Pollard TJ, Shen L, Lehman L, Feng M, Ghassemi M, Moody B, Szolovits P, Celi LA, and Mark RG. Scientific Data (2016). DOI: 10.1038/sdata.2016.35. Available at: http://www.nature.com/articles/sdata201635

The subset that we will be exploring is a single table which includes laboratory data and some demographic information.

Some important columns include:
- subject_id: Unique patient identifier
- hadm_id: Unique admission identifier
- charttime: Time of specimen collection
- curr_service: Name of service that sent the test

## EDA session organization

Each exercise is structured as follows:

1. There will be an explicit task
2. You will use functions we have learned to complete the task
3. You will be asked to answer a question-set based on your findings

## Exercise 0

Before we begin we have to load our library of functions that we'll be using. Since all of the necessary functions are included in the tidyverse family of packages, all we need to do is run the library() command on tidyverse.

- Use the code block below to run `library()` on "tidyverse"

```{r}
library(tidyverse)
```


## Exercise 1

So far so good. Now we need to get our data into the rstudio environment so that we can start poking at it. Relative to our current working directory the data is located in a subfolder called "data". The file is called "mimic.csv". 

- In the code block below use the `read_csv()` function to read this data file into a new data frame called "mimic"
- Take a look at the data frame. Use `summary()`. Press on the name of the data frame in the environment tab on the upper-right.

**HINT** check out how we loaded the menu/test_catalog data set in the second lesson!

```{r}
mimic <- read_csv("data/mimic.csv")

summary(mimic)
```

### Questions

1. How many rows are in the data frame?
2. How many columns are in the data frame?
3. What does each row in the data frame represent?
4. How many columns contain information about the patient's admission and how many relate to the test order?


## Exercise 2

OK now that we've got a sense for the shape of the data let's figure out what's inside of it. I like to start by testing my assumptions about the data set. The mimic data frame has results data for ICU patients. We will use some simple dplyr functions to better understand the patterns of data in the mimic data frame.

- Use `filter()` to find the rows that have NA in the valuenum column.
- Use `select()` to narrow down on just the "panel_test", "test_name", "component", "value" and "valuenum" columns.
- Use `arrange()` to order the data frame by "value" and "component" columns

```{r}
mimic %>% 
  filter(is.na(valuenum),
         !is.na(value)) %>% 
  select(panel_test, component, value,valuenum) %>%
  arrange((value),component) %>% View
  
```

1. What is the difference between the "value" and "valuenum" columns?
2. What kind of result values in the data set appear in the "value" column but are NA in the "valuenum" column?


## Exercise 3

Performing EDA often begins by looking at the distribution of data in each column. Perforce this is a little different depending on the data type in each column. Continuous data, like numeric data, could be looked at with histograms, whereas categorical data, like character strings, may be best viewed with a summary table with counts. Let's start with the columns with character type data.

- In the code block below, use `group_by()` and `summarize()` to get a sense for the kinds of data in some of the columns with character data.
- Use `n()` and `n_distinct` inside of the `summarize()` function to count the rows and distinct values in each group

**HINT** check out how we used these functions in the third lesson.

```{r}
mimic %>% 
  group_by(curr_service) %>% 
  summarise(n=n()) %>% 
  arrange(desc(n))
```

### Questions

1. How many distinct patients and admissions are in the data frame?
2. How many different panel tests and components are in the data frame?
3. What is the most common religion for patients in the data frame?
4. *Challenge Question* What is the most commonly ordered test in the data set.


## Show and Tell 1

An important part of EDA is knowing where you DON'T have data, that is where are the NA's in your data set. There are several packages in R that will help you answer this question as well as graph it for you, determine whether there are patterns to the missingess and lots more. Check out [naniar](https://github.com/njtierney/naniar) for one of the best out there. However, we can do a lot just with the tidyverse functions. 

- Run this code block
- There are three new functions
- See if you can determine what they are doing by stepping through the pipeline (use your mouse to highlight just the beginning of the code and press CTRL + Enter or CMD + Enter to just execute the highlighted code)

**HINT** remember from lesson 1 that you can type "?" before a function, execute it, and get a nifty help file in the lower right pane.

```{r}
mimic %>% 
  mutate_all(is.na) %>% 
  summarise_all(sum) %>% 
  gather() %>% 
  arrange(desc(value))
```

### Questions

1. How do `mutate_all()` and `summarize_all()` differ from `mutate()` and `summarize()`, respectively?
2. What does `gather()` do? How does the data frame look before it's been piped through, and after it's been piped through `gather()`?
3. What patterns do you see in the "missingness" in each of the columns?


## Exercise 4

OK, after having looked at some categorical variables and the distribution of NA's, let's have a look at some of the continous variables. In mimic we have the charttime, which is in a date time format, and we have the valuenum column. A very effective way to examine these kinds of data are with a histogram. Let's use our ggplotting skills to see what's going on in these columns

- use ggplot() to assess the distribution of **charttime**

```{r}



```



```{r}
mimic %>% 
  map_dbl(~sum(is.na(.)))
```


